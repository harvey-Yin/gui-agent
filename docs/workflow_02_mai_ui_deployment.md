# å·¥ä½œæµç¨‹æŠ¥å‘Š2: MAI-UIè§†è§‰æ¨¡å‹éƒ¨ç½²è°ƒè¯•

## ğŸ“‹ æµç¨‹æ¦‚è¿°

æœ¬æŠ¥å‘Šæ•´åˆäº†MAI-UI-2B/8Bæ¨¡å‹çš„Dockeréƒ¨ç½²ã€è°ƒè¯•å’Œé›†æˆçš„å®Œæ•´æµç¨‹ã€‚

---

## ğŸ¯ MAI-UIæ¨¡å‹ä»‹ç»

**MAI-UI** æ˜¯é˜¿é‡Œå·´å·´é€šä¹‰å®éªŒå®¤å¼€æºçš„GUIæ™ºèƒ½ä½“æ¨¡å‹ï¼Œå¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€+æˆªå›¾ç†è§£å¹¶æ“ä½œç”¨æˆ·ç•Œé¢ã€‚

- **HuggingFace**: https://huggingface.co/Tongyi-MAI/MAI-UI-8B
- **GitHub**: https://github.com/Tongyi-MAI/MAI-UI
- **æ¨ç†å¼•æ“**: vLLMï¼ˆé«˜æ€§èƒ½æ¨ç†ï¼‰
- **APIæ–¹å¼**: OpenAIå…¼å®¹æ¥å£

### æ¨¡å‹å¯¹æ¯”

| æŒ‡æ ‡ | MAI-UI-8B | MAI-UI-2B |
|------|-----------|-----------|
| å‚æ•°é‡ | 8B | 2B |
| æ˜¾å­˜å ç”¨ | 16.64 GB | 4.24 GB |
| 12GB GPUå…¼å®¹ | âŒ éœ€è¦é‡åŒ– | âœ… å®Œç¾è¿è¡Œ |
| åŠ è½½æ—¶é—´ | ~140ç§’ | ~45ç§’ |
| è¯†åˆ«å‡†ç¡®åº¦ | æ›´é«˜ | è¶³å¤Ÿç”¨ |
| æ¨èåœºæ™¯ | 24GB+ GPU | 12GB GPU |

**ç»“è®º**: å¯¹äº12GBæ˜¾å­˜ï¼ˆå¦‚RTX 4070ï¼‰ï¼Œæ¨èä½¿ç”¨MAI-UI-2Bã€‚

---

## ğŸš€ Dockeréƒ¨ç½²æµç¨‹ï¼ˆæ¨èæ–¹å¼ï¼‰

### Step 1: ç¯å¢ƒå‡†å¤‡

**ç³»ç»Ÿè¦æ±‚**:
- Windows 11 + Docker Desktop
- WSL2å·²å¯ç”¨
- NVIDIA GPUï¼ˆ12GB+æ˜¾å­˜ï¼‰
- CUDAæ”¯æŒ

**æ£€æŸ¥ç¯å¢ƒ**:
```powershell
# æ£€æŸ¥Docker
docker --version

# æ£€æŸ¥GPU
nvidia-smi

# æ£€æŸ¥WSL2
wsl --list --verbose
```

### Step 2: åˆ›å»ºdocker-compose.yml

**ä½ç½®**: `c:\document\python\gui-agent\gui-agent\docker-compose.yml`

```yaml
version: '3.8'

services:
  vllm-mai-ui:
    image: vllm/vllm-openai:latest
    container_name: mai-ui-2b-agent
    ports:
      - "8001:8000"
    environment:
      - HF_ENDPOINT=https://hf-mirror.com  # å›½å†…é•œåƒ
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ${USERPROFILE}/.cache/huggingface:/root/.cache/huggingface
    command: >
      --model Tongyi-MAI/MAI-UI-2B
      --served-model-name MAI-UI-2B
      --host 0.0.0.0
      --port 8000
      --trust-remote-code
      --dtype float16
      --gpu-memory-utilization 0.85
      --max-model-len 4096
      --enforce-eager
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/models"]
      interval: 30s
      timeout: 10s
      retries: 3
```

### Step 3: å¯åŠ¨æœåŠ¡

```powershell
# è¿›å…¥é¡¹ç›®ç›®å½•
cd c:\document\python\gui-agent\gui-agent

# å¯åŠ¨æœåŠ¡ï¼ˆé¦–æ¬¡ä¼šä¸‹è½½æ¨¡å‹ï¼Œéœ€è¦10-30åˆ†é’Ÿï¼‰
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f
```

**é¦–æ¬¡å¯åŠ¨æ—¥å¿—**:
```
INFO:     Started server process
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### Step 4: éªŒè¯æœåŠ¡

```powershell
# æ£€æŸ¥æ¨¡å‹åˆ—è¡¨
curl http://localhost:8001/v1/models

# æµ‹è¯•ç®€å•æ¨ç†
curl http://localhost:8001/v1/chat/completions `
  -H "Content-Type: application/json" `
  -d '{
    "model": "MAI-UI-2B",
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "max_tokens": 100
  }'
```

**é¢„æœŸè¾“å‡º**:
```json
{
  "id": "cmpl-xxx",
  "model": "MAI-UI-2B",
  "choices": [{
    "message": {
      "role": "assistant",
      "content": "ä½ å¥½ï¼æˆ‘æ˜¯MAI-UI..."
    }
  }]
}
```

---

## ğŸ§ª GUIè¯†åˆ«æµ‹è¯•

### æµ‹è¯•è„šæœ¬

**æ–‡ä»¶**: `test_mai_ui_api.py`

```python
import openai
import base64
from pathlib import Path

# é…ç½®API
client = openai.OpenAI(
    base_url="http://localhost:8001/v1",
    api_key="dummy"  # vLLMä¸éœ€è¦çœŸå®key
)

# è¯»å–æˆªå›¾
screenshot_path = "screenshot.png"
with open(screenshot_path, "rb") as f:
    image_base64 = base64.b64encode(f.read()).decode()

# è°ƒç”¨MAI-UI
response = client.chat.completions.create(
    model="MAI-UI-2B",
    messages=[{
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{image_base64}"
                }
            },
            {
                "type": "text",
                "text": "è¯·æè¿°è¿™ä¸ªç•Œé¢ä¸Šæœ‰ä»€ä¹ˆå…ƒç´ "
            }
        ]
    }],
    max_tokens=512
)

print(response.choices[0].message.content)
```

### æµ‹è¯•ç»“æœ

**è¯†åˆ«èƒ½åŠ›** âœ…:
- IDEç±»å‹ï¼ˆVS Codeï¼‰
- å½“å‰æ–‡ä»¶å
- æ–‡ä»¶åˆ—è¡¨
- Source Controlé¢æ¿
- Dockeré…ç½®è¯¦æƒ…
- æ–‡ä»¶ä¿®æ”¹çŠ¶æ€

**æ€§èƒ½æŒ‡æ ‡**:
- æ¨¡å‹åŠ è½½æ—¶é—´: ~45ç§’
- æ¨ç†é€Ÿåº¦: ~5-10ç§’/è¯·æ±‚
- æ˜¾å­˜å ç”¨: 4.24 GB / 12 GB

---

## ğŸ”§ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### é—®é¢˜1: æ˜¾å­˜ä¸è¶³ (OOM)

**ç—‡çŠ¶**: 
```
torch.cuda.OutOfMemoryError: CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆ**:

**æ–¹æ¡ˆA: é™ä½æ˜¾å­˜åˆ©ç”¨ç‡**
```yaml
command: >
  --gpu-memory-utilization 0.75  # ä»0.85é™åˆ°0.75
```

**æ–¹æ¡ˆB: å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦**
```yaml
command: >
  --max-model-len 2048  # ä»4096é™åˆ°2048
```

**æ–¹æ¡ˆC: ä½¿ç”¨MAI-UI-2Bä»£æ›¿8B**
```yaml
command: >
  --model Tongyi-MAI/MAI-UI-2B  # æ˜¾å­˜éœ€æ±‚4GB vs 17GB
```

### é—®é¢˜2: æ¨¡å‹ä¸‹è½½å¤±è´¥

**ç—‡çŠ¶**:
```
HTTPSConnectionPool: Max retries exceeded
```

**è§£å†³æ–¹æ¡ˆ**:

**æ–¹æ¡ˆA: ä½¿ç”¨å›½å†…é•œåƒ**
```yaml
environment:
  - HF_ENDPOINT=https://hf-mirror.com
```

**æ–¹æ¡ˆB: æ‰‹åŠ¨é¢„ä¸‹è½½**
```powershell
# å®‰è£…huggingface-cli
pip install huggingface-hub

# ä¸‹è½½æ¨¡å‹
huggingface-cli download Tongyi-MAI/MAI-UI-2B --local-dir ./models/MAI-UI-2B

# ä¿®æ”¹docker-compose.ymlä½¿ç”¨æœ¬åœ°è·¯å¾„
command: >
  --model /models/MAI-UI-2B
```

### é—®é¢˜3: Dockerå®¹å™¨å¯åŠ¨å¤±è´¥

**ç—‡çŠ¶**:
```
Error response from daemon: could not select device driver "nvidia"
```

**è§£å†³æ–¹æ¡ˆ**:

1. **å®‰è£…NVIDIA Container Toolkit**
```powershell
# åœ¨WSL2ä¸­å®‰è£…
wsl
sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

2. **æ£€æŸ¥Docker Desktopè®¾ç½®**
- æ‰“å¼€Docker Desktop
- Settings â†’ Resources â†’ WSL Integration
- å¯ç”¨WSL2é›†æˆ

3. **éªŒè¯GPUå¯ç”¨æ€§**
```powershell
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

### é—®é¢˜4: APIå“åº”æ…¢

**ç—‡çŠ¶**: æ¨ç†æ—¶é—´è¶…è¿‡30ç§’

**è§£å†³æ–¹æ¡ˆ**:

**æ–¹æ¡ˆA: å¯ç”¨CUDA Graphs**ï¼ˆéœ€è¦æ›´å¤šæ˜¾å­˜ï¼‰
```yaml
command: >
  # ç§»é™¤ --enforce-eager
```

**æ–¹æ¡ˆB: å¢åŠ tensorå¹¶è¡Œ**ï¼ˆå¤šGPUï¼‰
```yaml
command: >
  --tensor-parallel-size 2  # ä½¿ç”¨2ä¸ªGPU
```

**æ–¹æ¡ˆC: å‡å°‘max_tokens**
```python
response = client.chat.completions.create(
    max_tokens=256  # ä»512é™åˆ°256
)
```

---

## ğŸ”— é›†æˆåˆ°RPAé¡¹ç›®

### æ–¹å¼1: å°è£…ä¸ºRPAå·¥å…·

**æ–‡ä»¶**: `rpa_tools/mai_ui_vision.py`

```python
import openai
import base64
from typing import Dict, Any
from .base_tool import RPAToolBase

class MAIUIVisionTool(RPAToolBase):
    """MAI-UIè§†è§‰è¯†åˆ«å·¥å…·"""
    
    def __init__(self, api_base="http://localhost:8001/v1"):
        super().__init__()
        self.description = "ä½¿ç”¨MAI-UIæ¨¡å‹è¯†åˆ«GUIå…ƒç´ "
        self.client = openai.OpenAI(base_url=api_base, api_key="dummy")
    
    def execute(self, screenshot_path: str, instruction: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨MAI-UIè¯†åˆ«GUIå…ƒç´ 
        
        Args:
            screenshot_path: æˆªå›¾æ–‡ä»¶è·¯å¾„
            instruction: è¯†åˆ«æŒ‡ä»¤ï¼ˆå¦‚"æ‰¾åˆ°ç™»å½•æŒ‰é’®"ï¼‰
        """
        try:
            # è¯»å–æˆªå›¾
            with open(screenshot_path, "rb") as f:
                image_base64 = base64.b64encode(f.read()).decode()
            
            # è°ƒç”¨MAI-UI
            response = self.client.chat.completions.create(
                model="MAI-UI-2B",
                messages=[{
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{image_base64}"
                            }
                        },
                        {"type": "text", "text": instruction}
                    ]
                }],
                max_tokens=512
            )
            
            result_text = response.choices[0].message.content
            
            return {
                "status": "success",
                "result": result_text,
                "message": f"MAI-UIè¯†åˆ«å®Œæˆ: {result_text[:100]}..."
            }
        except Exception as e:
            return {"status": "error", "message": str(e)}
```

### æ–¹å¼2: åœ¨Agentä¸­ä½¿ç”¨

```python
from rpa_tools import get_rpa_tools, MAIUIVisionTool

# æ³¨å†ŒMAI-UIå·¥å…·
mai_ui_tool = MAIUIVisionTool()
tools = get_rpa_tools() + [mai_ui_tool]

# åœ¨Agentä¸­ä½¿ç”¨
agent = create_react_agent(llm, tools, prompt)
result = agent.invoke({
    "input": "æˆªå›¾å½“å‰å±å¹•ï¼Œç„¶åæ‰¾åˆ°ç™»å½•æŒ‰é’®å¹¶ç‚¹å‡»"
})
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### é’ˆå¯¹12GBæ˜¾å­˜çš„æœ€ä½³é…ç½®

```yaml
command: >
  --model Tongyi-MAI/MAI-UI-2B
  --gpu-memory-utilization 0.85
  --max-model-len 4096
  --enforce-eager
  --dtype float16
```

**å…³é”®å‚æ•°è¯´æ˜**:
- `max-model-len 4096`: æ”¯æŒè§†è§‰è¯­è¨€è¾“å…¥
- `gpu-memory-utilization 0.85`: ç•™15%ç»™ç³»ç»Ÿ
- `enforce-eager`: ç¦ç”¨CUDA GraphsèŠ‚çœæ˜¾å­˜

### æ€§èƒ½å¯¹æ¯”

| é…ç½® | æ˜¾å­˜å ç”¨ | åŠ è½½æ—¶é—´ | æ¨ç†é€Ÿåº¦ |
|------|---------|---------|---------|
| é»˜è®¤é…ç½® | 9.2 GB | ~60s | ~8s |
| ä¼˜åŒ–é…ç½® | 4.24 GB | ~45s | ~5s |
| é‡åŒ–INT8 | 2.8 GB | ~50s | ~12s |

---

## âœ… éƒ¨ç½²æˆåŠŸæ ‡å¿—

1. **Dockerå®¹å™¨è¿è¡Œä¸­**
```powershell
docker ps
# åº”è¯¥çœ‹åˆ° mai-ui-2b-agent å®¹å™¨
```

2. **APIå“åº”æ­£å¸¸**
```powershell
curl http://localhost:8001/v1/models
# è¿”å›æ¨¡å‹åˆ—è¡¨
```

3. **GUIè¯†åˆ«æµ‹è¯•é€šè¿‡**
```powershell
python test_mai_ui_api.py
# æˆåŠŸè¯†åˆ«æˆªå›¾å†…å®¹
```

4. **æ˜¾å­˜å ç”¨åˆç†**
```powershell
nvidia-smi
# GPUæ˜¾å­˜å ç”¨ < 6GB
```

---

## ğŸ“ ä¸‹ä¸€æ­¥

### é€‰é¡¹A: æ·±å…¥MAI-UIåº”ç”¨
- [ ] æµ‹è¯•æ›´å¤šGUIè¯†åˆ«åœºæ™¯
- [ ] ä¼˜åŒ–promptæé«˜å‡†ç¡®ç‡
- [ ] å°è£…ä¸ºå®Œæ•´çš„RPAå·¥å…·ç±»
- [ ] é›†æˆåˆ°Agentå·¥ä½œæµ

### é€‰é¡¹B: å›å½’RPAé¡¹ç›®ä¸»çº¿
- [ ] Phase 2: å¼€å‘Agentæ ¸å¿ƒ
- [ ] é›†æˆqwen:7bï¼ˆå·²éªŒè¯ï¼‰
- [ ] å®ç°ç¬¬ä¸€ä¸ªAgent Demo
- [ ] MAI-UIä½œä¸ºé«˜çº§ç‰¹æ€§åæœŸé›†æˆ

**æ¨è**: é€‰Bï¼ŒMAI-UIå·²éªŒè¯å¯ç”¨ï¼Œå¯ä½œä¸ºå¢å¼ºåŠŸèƒ½åæœŸé›†æˆã€‚

---

## ğŸ†˜ æ•…éšœæ’æŸ¥æ¸…å•

| é—®é¢˜ | æ£€æŸ¥é¡¹ | è§£å†³æ–¹æ¡ˆ |
|------|--------|---------|
| å®¹å™¨æ— æ³•å¯åŠ¨ | Docker Desktopè¿è¡Œï¼Ÿ | å¯åŠ¨Docker Desktop |
| GPUä¸å¯ç”¨ | nvidia-smiæ­£å¸¸ï¼Ÿ | å®‰è£…NVIDIAé©±åŠ¨ |
| æ˜¾å­˜ä¸è¶³ | æ˜¾å­˜å ç”¨ï¼Ÿ | é™ä½gpu-memory-utilization |
| ä¸‹è½½å¤±è´¥ | ç½‘ç»œè¿æ¥ï¼Ÿ | ä½¿ç”¨HFé•œåƒ |
| APIæ— å“åº” | ç«¯å£å†²çªï¼Ÿ | æ£€æŸ¥8001ç«¯å£å ç”¨ |

---

**éƒ¨ç½²å®Œæˆï¼ç°åœ¨å¯ä»¥åœ¨RPAé¡¹ç›®ä¸­ä½¿ç”¨MAI-UIçš„å¼ºå¤§è§†è§‰è¯†åˆ«èƒ½åŠ›äº†ï¼** ğŸ‰
