# MAI-UI-8B æœ¬åœ°éƒ¨ç½²å®Œæ•´æŒ‡å—

## ğŸ“‹ éƒ¨ç½²æ¦‚è¿°

**MAI-UI-8B** æ˜¯é˜¿é‡Œå·´å·´é€šä¹‰å®éªŒå®¤å¼€æºçš„GUIæ™ºèƒ½ä½“æ¨¡å‹ï¼Œå¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€+æˆªå›¾ç†è§£å¹¶æ“ä½œç”¨æˆ·ç•Œé¢ã€‚

- **æ¨¡å‹å¤§å°**: 8Bå‚æ•°
- **æ¨ç†å¼•æ“**: vLLMï¼ˆé«˜æ€§èƒ½æ¨ç†ï¼‰
- **APIæ–¹å¼**: OpenAIå…¼å®¹æ¥å£
- **HuggingFace**: https://huggingface.co/Tongyi-MAI/MAI-UI-8B

---

## âš™ï¸ ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- **GPU**: æ¨èNVIDIA GPUï¼ˆæ˜¾å­˜16GB+ï¼‰
  - RTX 3090 / RTX 4090 / A100ç­‰
  - æ”¯æŒCUDA
- **å†…å­˜**: 32GB+
- **ç¡¬ç›˜**: 20GB+ï¼ˆå­˜å‚¨æ¨¡å‹ï¼‰

### è½¯ä»¶è¦æ±‚
- Python 3.10+
- CUDA 11.8+ / 12.1+
- Git

---

## ğŸš€ å®Œæ•´éƒ¨ç½²æ­¥éª¤

### Step 1: æ£€æŸ¥ç¯å¢ƒ

```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬
python --version  # åº”è¯¥æ˜¯ 3.10+

# æ£€æŸ¥CUDAï¼ˆå¦‚æœ‰GPUï¼‰
nvidia-smi

# æ£€æŸ¥Git
git --version
```

### Step 2: åˆ›å»ºç‹¬ç«‹è™šæ‹Ÿç¯å¢ƒ

**ä¸ºä»€ä¹ˆç‹¬ç«‹ç¯å¢ƒï¼Ÿ** MAI-UIéœ€è¦ç‰¹å®šç‰ˆæœ¬çš„ä¾èµ–ï¼Œé¿å…ä¸ç°æœ‰RPAé¡¹ç›®å†²çªã€‚

```bash
# åœ¨åˆé€‚çš„ä½ç½®åˆ›å»ºMAI-UIé¡¹ç›®ç›®å½•
cd c:\document\python
mkdir mai-ui-deploy
cd mai-ui-deploy

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv_mai

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
venv_mai\Scripts\activate
```

### Step 3: å®‰è£…vLLMå’Œä¾èµ–

vLLMæ˜¯é«˜æ€§èƒ½LLMæ¨ç†å¼•æ“ï¼Œæ”¯æŒOpenAIå…¼å®¹APIã€‚

```bash
# å‡çº§pip
python -m pip install --upgrade pip

# å®‰è£…vLLMï¼ˆéœ€è¦æ—¶é—´ï¼Œçº¦5-10åˆ†é’Ÿï¼‰
pip install vllm>=0.11.0

# å®‰è£…transformers
pip install transformers>=4.57.0

# å®‰è£…å…¶ä»–ä¾èµ–
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**æ³¨æ„**ï¼š
- å¦‚æœæ²¡æœ‰GPUï¼ŒvLLMå¯èƒ½æ— æ³•ä½¿ç”¨ï¼Œéœ€è¦ä½¿ç”¨CPUç‰ˆæœ¬ï¼ˆæ€§èƒ½è¾ƒå·®ï¼‰
- CUDAç‰ˆæœ¬æ ¹æ®ä½ çš„GPUé©±åŠ¨é€‰æ‹©ï¼ˆcu118æˆ–cu121ï¼‰

### Step 4: ä¸‹è½½MAI-UI-8Bæ¨¡å‹

**æ–¹å¼Aï¼šè‡ªåŠ¨ä¸‹è½½ï¼ˆæ¨èï¼‰**

vLLMä¼šåœ¨é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨ä»HuggingFaceä¸‹è½½æ¨¡å‹ã€‚

**æ–¹å¼Bï¼šæ‰‹åŠ¨é¢„ä¸‹è½½ï¼ˆå¯é€‰ï¼‰**

```bash
# å®‰è£…huggingface-cli
pip install huggingface-hub

# ç™»å½•ï¼ˆå¦‚éœ€è®¿é—®ç§æœ‰æ¨¡å‹ï¼‰
huggingface-cli login

# ä¸‹è½½æ¨¡å‹ï¼ˆçº¦16GBï¼Œéœ€è¦æ—¶é—´ï¼‰
huggingface-cli download Tongyi-MAI/MAI-UI-8B --local-dir ./models/MAI-UI-8B
```

### Step 5: å¯åŠ¨vLLM APIæœåŠ¡å™¨

```bash
# ç¡®ä¿è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»
venv_mai\Scripts\activate

# å¯åŠ¨vLLMæœåŠ¡ï¼ˆè‡ªåŠ¨ä¸‹è½½æ¨¡å¼ï¼‰
python -m vllm.entrypoints.openai.api_server \
  --model Tongyi-MAI/MAI-UI-8B \
  --served-model-name MAI-UI-8B \
  --host 0.0.0.0 \
  --port 8001 \
  --tensor-parallel-size 1 \
  --trust-remote-code
```

**å‚æ•°è¯´æ˜**ï¼š
- `--model`: æ¨¡å‹è·¯å¾„ï¼ˆHuggingFace IDæˆ–æœ¬åœ°è·¯å¾„ï¼‰
- `--port 8001`: APIç«¯å£ï¼ˆé¿å…ä¸ç°æœ‰é¡¹ç›®çš„8000å†²çªï¼‰
- `--tensor-parallel-size 1`: å•GPUæ¨ç†ï¼ˆå¤šGPUæ”¹ä¸º2ã€4ã€8ç­‰ï¼‰
- `--trust-remote-code`: å…è®¸æ‰§è¡Œæ¨¡å‹è‡ªå®šä¹‰ä»£ç 

**é¦–æ¬¡è¿è¡Œ**ï¼š
- vLLMä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹åˆ° `~/.cache/huggingface/`
- ä¸‹è½½è¿‡ç¨‹å¯èƒ½éœ€è¦10-30åˆ†é’Ÿï¼ˆå–å†³äºç½‘ç»œï¼‰
- ä¸‹è½½å®Œæˆåä¼šåŠ è½½æ¨¡å‹åˆ°GPU

**æˆåŠŸæ ‡å¿—**ï¼š
```
INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)
```

### Step 6: æµ‹è¯•APIæœåŠ¡

**æ–°å¼€ä¸€ä¸ªç»ˆç«¯**ï¼Œæµ‹è¯•APIæ˜¯å¦æ­£å¸¸ï¼š

```bash
# æŸ¥çœ‹æ¨¡å‹åˆ—è¡¨
curl http://localhost:8001/v1/models

# æµ‹è¯•ç®€å•æ¨ç†
curl http://localhost:8001/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "MAI-UI-8B",
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "max_tokens": 100
  }'
```

é¢„æœŸè¾“å‡ºï¼š
```json
{
  "id": "...",
  "model": "MAI-UI-8B",
  "choices": [
    {
      "message": {
        "role": "assistant",
        "content": "ä½ å¥½ï¼æˆ‘æ˜¯MAI-UI..."
      }
    }
  ]
}
```

---

## ğŸ§ª ç¬¬ä¸€æ¬¡è¿è¡Œï¼šGUIè¯†åˆ«æµ‹è¯•

### å®‰è£…MAI-UIå·¥å…·åŒ…

```bash
# å…‹éš†MAI-UIå®˜æ–¹ä»£ç åº“
git clone https://github.com/Tongyi-MAI/MAI-UI.git
cd MAI-UI

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å¯åŠ¨Jupyter
pip install jupyter
jupyter notebook
```

### è¿è¡ŒGrounding Demo

1. æ‰“å¼€ `cookbook/grounding.ipynb`
2. ä¿®æ”¹APIåœ°å€ï¼š
   ```python
   agent = MAIGroundingAgent(
       llm_base_url="http://localhost:8001/v1",  # ä½ çš„vLLMåœ°å€
       model_name="MAI-UI-8B",
       runtime_conf={
           "history_n": 3,
           "temperature": 0.0,
           "max_tokens": 2048,
       },
   )
   ```
3. è¿è¡Œæ‰€æœ‰å•å…ƒæ ¼
4. æä¾›ä¸€å¼ æˆªå›¾ + è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼ˆå¦‚"ç‚¹å‡»ç™»å½•æŒ‰é’®"ï¼‰
5. æ¨¡å‹ä¼šè¿”å›UIå…ƒç´ çš„ä½ç½®åæ ‡

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: æ˜¾å­˜ä¸å¤Ÿæ€ä¹ˆåŠï¼Ÿ

**æ–¹æ¡ˆ1ï¼šé‡åŒ–æ¨¡å‹**
```bash
# ä½¿ç”¨INT8é‡åŒ–
python -m vllm.entrypoints.openai.api_server \
  --model Tongyi-MAI/MAI-UI-8B \
  --quantization int8 \
  --port 8001
```

**æ–¹æ¡ˆ2ï¼šä½¿ç”¨MAI-UI-2B**
```bash
# ä½¿ç”¨æ›´å°çš„2Bæ¨¡å‹ï¼ˆæ˜¾å­˜éœ€æ±‚çº¦4-6GBï¼‰
python -m vllm.entrypoints.openai.api_server \
  --model Tongyi-MAI/MAI-UI-2B \
  --port 8001
```

### Q2: ä¸‹è½½é€Ÿåº¦æ…¢ï¼Ÿ

**ä½¿ç”¨å›½å†…é•œåƒ**ï¼š
```bash
# è®¾ç½®HuggingFaceé•œåƒï¼ˆå¯é€‰ï¼‰
export HF_ENDPOINT=https://hf-mirror.com
```

### Q3: æ²¡æœ‰GPUèƒ½ç”¨å—ï¼Ÿ

**CPUæ¨¡å¼**ï¼ˆé€Ÿåº¦éå¸¸æ…¢ï¼Œä¸æ¨èï¼‰ï¼š
```bash
pip install vllm-cpu
# æˆ–ä½¿ç”¨transformersç›´æ¥åŠ è½½
```

### Q4: å¦‚ä½•åœæ­¢æœåŠ¡ï¼Ÿ

åœ¨vLLMæœåŠ¡å™¨ç»ˆç«¯æŒ‰ `Ctrl+C`

---

## ğŸ“Š æ€§èƒ½é¢„æœŸ

| ç¡¬ä»¶ | é¦–æ¬¡åŠ è½½ | å•æ¬¡æ¨ç† | æ˜¾å­˜å ç”¨ |
|------|----------|----------|----------|
| RTX 4090 | ~30ç§’ | ~2-5ç§’ | ~15GB |
| RTX 3090 | ~40ç§’ | ~3-7ç§’ | ~16GB |
| A100 | ~20ç§’ | ~1-3ç§’ | ~15GB |

---

## ğŸ¯ ä¸ä½ çš„RPAé¡¹ç›®é›†æˆ

éƒ¨ç½²æˆåŠŸåï¼Œå¯ä»¥åœ¨ä½ çš„RPA Agentä¸­è°ƒç”¨MAI-UIï¼š

```python
# åœ¨ä½ çš„é¡¹ç›®ä¸­
import httpx
import base64

class MAIUIVisionTool:
    def __init__(self):
        self.api_url = "http://localhost:8001/v1"
    
    async def locate_element(self, screenshot_path: str, instruction: str):
        """ä½¿ç”¨MAI-UIå®šä½UIå…ƒç´ """
        
        # è¯»å–æˆªå›¾å¹¶è½¬ä¸ºbase64
        with open(screenshot_path, 'rb') as f:
            img_base64 = base64.b64encode(f.read()).decode()
        
        # è°ƒç”¨MAI-UI API
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.api_url}/chat/completions",
                json={
                    "model": "MAI-UI-8B",
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": instruction},
                                {"type": "image_url", "image_url": f"data:image/png;base64,{img_base64}"}
                            ]
                        }
                    ],
                    "max_tokens": 512
                }
            )
            result = response.json()
            # è§£æè¿”å›çš„åæ ‡
            return result
```

---

## ğŸ“ ä¸‹ä¸€æ­¥

1. **æµ‹è¯•GroundingåŠŸèƒ½**ï¼šè¯†åˆ«UIå…ƒç´ ä½ç½®
2. **æµ‹è¯•NavigationåŠŸèƒ½**ï¼šå®Œæ•´ä»»åŠ¡æ‰§è¡Œ
3. **é›†æˆåˆ°RPAé¡¹ç›®**ï¼šä½œä¸ºè§†è§‰è¯†åˆ«çš„å¢å¼ºæ–¹æ¡ˆ
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šè°ƒæ•´batch_sizeã€temperatureç­‰å‚æ•°

---

## ğŸ†˜ è·å–å¸®åŠ©

- GitHub Issue: https://github.com/Tongyi-MAI/MAI-UI/issues
- HuggingFaceè®¨è®º: https://huggingface.co/Tongyi-MAI/MAI-UI-8B/discussions
- å®˜æ–¹æ–‡æ¡£: æŸ¥çœ‹README.md

---

**éƒ¨ç½²å®Œæˆåå‘Šè¯‰æˆ‘ï¼Œæˆ‘ä»¬å¯ä»¥ä¸€èµ·æµ‹è¯•ç¬¬ä¸€ä¸ªGUIè¯†åˆ«ä»»åŠ¡ï¼** ğŸ‰
